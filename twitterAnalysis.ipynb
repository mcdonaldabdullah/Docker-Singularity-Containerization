{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\spark\\\\spark-3.0.0-preview2-bin-hadoop2.7'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import SQLContext, SparkSession\n",
    "from pyspark.sql.functions import desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating spark, streaming and SQL context\n",
    "spark_context = SparkContext()\n",
    "streaming_context = StreamingContext(spark_context, 10)\n",
    "sqlContext = SQLContext(spark_context)\n",
    "spark = SparkSession.builder.appName('Sparksql').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate streaming text from a TCP (socket) source:\n",
    "tcp_socket_stream = streaming_context.socketTextStream(\"127.0.0.1\", 5555)\n",
    "# RDDs that contain the tweets with socket_stream window of size 60, or 60 #seconds windows of time\n",
    "rdds = tcp_socket_stream.window(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "#creating a function to remove all punctuation from the tweets\n",
    "def remove_punctuation(text):\n",
    "    no_punc_text = \"\".join([t for t in text if t not in string.punctuation])\n",
    "    return no_punc_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "fields = (\"word\", \"count\")\n",
    "Tweet = namedtuple( 'Tweet', fields )\n",
    "\n",
    "(rdds.map(lambda text: remove_punctuation(text)) #this removes punctuation from every tweets before its stored in the RDDs\n",
    " .flatMap( lambda text: text.split( \" \" ) ) #Splits to a list\n",
    " .filter(lambda word: word.lower()) \n",
    " .map( lambda word: (word, 1))\n",
    "  .reduceByKey( lambda a, b: a + b )\n",
    "  .map( lambda rec: Tweet( rec[0], rec[1]))\n",
    "  .foreachRDD( lambda rdd: rdd.toDF().sort(\"count\").createOrReplaceTempView(\"tweets\") )) #creating a temp SQL table so that the words in the tweets can be easily accessed later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run 'requestTweets.py' file now.\n",
    "After starting the Streaming Context, wait 5 minutes so that enough tweets are collected before querying the SQL Context and doing the analysis of the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#streaming has started and we the tweets are now being saved into the RDDs \n",
    "streaming_context.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n",
      "|              word|count|\n",
      "+------------------+-----+\n",
      "|           brought|    1|\n",
      "|           article|    1|\n",
      "|        10monthold|    1|\n",
      "|          kpolantz|    1|\n",
      "|            police|    1|\n",
      "|               pa…|    1|\n",
      "|          ThankYou|    1|\n",
      "|httpstcoV57Lg46XWw|    1|\n",
      "|          these…RT|    1|\n",
      "|          overstay|    1|\n",
      "|            Having|    1|\n",
      "|            Liste…|    1|\n",
      "|         Employees|    1|\n",
      "|            mkraju|    1|\n",
      "|          German’s|    1|\n",
      "|              Food|    1|\n",
      "|              Meat|    1|\n",
      "|    administration|    1|\n",
      "|        Processing|    1|\n",
      "|            CNN…RT|    1|\n",
      "+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "structured_DB = sqlContext.sql( 'Select word, count from tweets' ) #filtering the SQL table by word and count so that we can analyze the results\n",
    "structured_DB.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweetsDB = structured_DB.toPandas() #converts filtered SQL table to Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['word', 'count']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_tweetsDB.columns.values) #listing the column names of the Pandas DataFrame so that we know what we working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_tweetsDB) #print the type of the dataframe to make sure its a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function removes all the website links from the tweets/words\n",
    "def clean_data(df):\n",
    "    result=[]\n",
    "    for index, row in df_tweetsDB.iterrows():\n",
    "        if (\"https\" not in row.word):\n",
    "            result.append(str(row.word.lower()))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kumar',\n",
       " 'research',\n",
       " 'administrator',\n",
       " 'twometerrule',\n",
       " 'hedge',\n",
       " 'regarding',\n",
       " 'visa',\n",
       " 'uae',\n",
       " 'wrapped',\n",
       " 'plastic',\n",
       " 'talking',\n",
       " 'resurgence…rt',\n",
       " 'thought',\n",
       " 'focusing',\n",
       " 'o…rt',\n",
       " 'whowhat',\n",
       " 'globalwitness',\n",
       " 'eu',\n",
       " 'cannot',\n",
       " 'wed',\n",
       " 'like',\n",
       " 'debkilroy',\n",
       " 'i”m',\n",
       " 'result',\n",
       " 'among',\n",
       " 'save',\n",
       " 'assanges',\n",
       " 'hes',\n",
       " 'lung',\n",
       " 'no',\n",
       " 'cases',\n",
       " 'tourists',\n",
       " 'v…',\n",
       " 'respiratory',\n",
       " 'droplet',\n",
       " 'dissemination',\n",
       " 'bbcrealitycheck',\n",
       " 'came',\n",
       " 'pregnant',\n",
       " 'b52malmet',\n",
       " 'w…rt',\n",
       " 'towards',\n",
       " 'them',\n",
       " 'etsy',\n",
       " 'turn',\n",
       " 'offers',\n",
       " 'therapy',\n",
       " 'interesting',\n",
       " 'osha',\n",
       " 'owner',\n",
       " 'he',\n",
       " 'worke…',\n",
       " 'amidst',\n",
       " 'vada',\n",
       " 'pav',\n",
       " '“feed',\n",
       " 'arabtimeskuwait',\n",
       " 'infections',\n",
       " 'mojahedineng',\n",
       " 'novel',\n",
       " '334',\n",
       " 'letha…rt',\n",
       " 'thehindu',\n",
       " 'claimed',\n",
       " '‘fight',\n",
       " 'cs’',\n",
       " 'traders',\n",
       " 'loss',\n",
       " 'incident…',\n",
       " 'tracing',\n",
       " 'happen',\n",
       " 'getting',\n",
       " 'want',\n",
       " 'milords',\n",
       " 'alert',\n",
       " 'ever',\n",
       " 'prayers',\n",
       " 'anytime',\n",
       " 'pump',\n",
       " 'economy',\n",
       " 'heartbreaking',\n",
       " 'carolina',\n",
       " 'isolated',\n",
       " 'during…analysis',\n",
       " 'scotgov',\n",
       " 'below',\n",
       " 'book',\n",
       " 'feces',\n",
       " 'septa’s',\n",
       " 'tougher',\n",
       " 'both',\n",
       " 'ebola',\n",
       " 'revenues',\n",
       " 'official',\n",
       " 'inspirational',\n",
       " 'menudeldía',\n",
       " 'korea',\n",
       " 'allkeyshop',\n",
       " 'join',\n",
       " 'staf…',\n",
       " 'where',\n",
       " 'sun',\n",
       " 'h…i',\n",
       " 'bullied',\n",
       " 'monthly',\n",
       " 'record',\n",
       " 'underl…',\n",
       " 'test',\n",
       " 'supports',\n",
       " 'new…',\n",
       " 'house',\n",
       " 'preferential',\n",
       " 'scotgov',\n",
       " 'start',\n",
       " 'mrna',\n",
       " '24',\n",
       " 'hours',\n",
       " 'until',\n",
       " 'staged',\n",
       " 'watch',\n",
       " 'ho…rt',\n",
       " 'app',\n",
       " 'green',\n",
       " 'would',\n",
       " 'certificate',\n",
       " 'flying',\n",
       " 'hairstylists',\n",
       " 'two',\n",
       " 'vaping',\n",
       " 'emergency',\n",
       " 'amazon',\n",
       " 'quality',\n",
       " 'servicewarehousereit',\n",
       " 'theaters',\n",
       " 'set',\n",
       " 'reopen',\n",
       " 'showtimes',\n",
       " '…',\n",
       " 'furlough',\n",
       " 'pay',\n",
       " 'work',\n",
       " 'fro…',\n",
       " 'must',\n",
       " 'others',\n",
       " 'asia',\n",
       " 'wouldn’t',\n",
       " 'two',\n",
       " 'institutes',\n",
       " 'developed',\n",
       " 'doesn’t…heres',\n",
       " 'wear',\n",
       " 'when',\n",
       " 'head',\n",
       " 'watching',\n",
       " 'events',\n",
       " 'lecturer',\n",
       " 'women',\n",
       " 'staff',\n",
       " 'oht20media',\n",
       " 'graphical',\n",
       " 'beating',\n",
       " 'there',\n",
       " 'promoting',\n",
       " 'neverforgive',\n",
       " 'chinaisterrorists',\n",
       " 'proves',\n",
       " 'coas…mr',\n",
       " 'pa…',\n",
       " 'evidence',\n",
       " 'happens',\n",
       " 'overstay',\n",
       " 'tourist',\n",
       " 'liste…',\n",
       " 'onlyyoontv',\n",
       " 'team',\n",
       " 'kpolantz',\n",
       " 'mkraju',\n",
       " 'evanperez',\n",
       " 'food',\n",
       " 'almost',\n",
       " 'administration',\n",
       " 'death',\n",
       " 'cnn…rt',\n",
       " 'brought',\n",
       " '10monthold',\n",
       " 'police',\n",
       " 'thankyou',\n",
       " 'these…rt',\n",
       " 'having',\n",
       " 'employees',\n",
       " 'german’s',\n",
       " 'meat',\n",
       " 'processing',\n",
       " 'rhinewe…',\n",
       " 'julian',\n",
       " 'chronic',\n",
       " 'theres',\n",
       " 'context',\n",
       " 'few',\n",
       " 'borders',\n",
       " 'stayhome',\n",
       " 'stayhomestaysafe…',\n",
       " 'article',\n",
       " 'yvonne',\n",
       " 'panacea',\n",
       " 'coronavi…bbcworld',\n",
       " 'wrong',\n",
       " 'time',\n",
       " 'laments',\n",
       " 'fauci',\n",
       " 'still',\n",
       " 'in',\n",
       " 'show',\n",
       " 'thuddy',\n",
       " 'red',\n",
       " 'black',\n",
       " 'hand',\n",
       " 'loc…',\n",
       " 'affimer',\n",
       " 'workers',\n",
       " '10k',\n",
       " 'venkatesh',\n",
       " 'iyer',\n",
       " 'goli',\n",
       " 'taken',\n",
       " 'hungry…rt',\n",
       " 'coronavirusupdate',\n",
       " 'htt…rt',\n",
       " '52800',\n",
       " 'checkered',\n",
       " 'iran’s',\n",
       " '31',\n",
       " 'heartbreak',\n",
       " '7',\n",
       " 'tontodikeh',\n",
       " 'off',\n",
       " 'your…ondo',\n",
       " 'incident',\n",
       " 'over',\n",
       " 'ahead',\n",
       " 'sto…',\n",
       " 'learn',\n",
       " 'did',\n",
       " 'stay',\n",
       " 'mass',\n",
       " 'reasonthe',\n",
       " 'bank',\n",
       " 'england',\n",
       " 'extra',\n",
       " 'expanding',\n",
       " 'bondbuying',\n",
       " 'struggle',\n",
       " 'double',\n",
       " 'mild',\n",
       " 'fluids',\n",
       " 'dirtiest',\n",
       " 'more…',\n",
       " 'faces',\n",
       " 'access',\n",
       " 'food',\n",
       " 'ambassador',\n",
       " 'campaign',\n",
       " 'bromleywell',\n",
       " 'info',\n",
       " 'govuk',\n",
       " 'usnavy',\n",
       " 'us',\n",
       " 'media',\n",
       " 'fight',\n",
       " 'allunitedagainstcov…how',\n",
       " 'stick',\n",
       " 'greghilburn1',\n",
       " 'louisianagov',\n",
       " 'employees',\n",
       " 'to…rt',\n",
       " '177',\n",
       " 'rise',\n",
       " 'tuesday',\n",
       " 'surge',\n",
       " 'clinical',\n",
       " 'trace',\n",
       " 'defund',\n",
       " 'leo',\n",
       " 'interestfree',\n",
       " 'repayment',\n",
       " 'free…',\n",
       " 'from',\n",
       " 'summary',\n",
       " 'allowed',\n",
       " 'coming',\n",
       " 'gets',\n",
       " 'humans',\n",
       " 't',\n",
       " 'iingwen',\n",
       " 'democracy',\n",
       " 'aodemocracies',\n",
       " 'ehteraz',\n",
       " 'qatarbased',\n",
       " '…rt',\n",
       " 'government',\n",
       " 'negative',\n",
       " 'nris',\n",
       " 'missouri',\n",
       " 'positive',\n",
       " 'hairstylists',\n",
       " 'served…',\n",
       " 'content',\n",
       " 'are',\n",
       " 'daraz',\n",
       " 'raise',\n",
       " 'abandoned',\n",
       " 'released',\n",
       " 'employee',\n",
       " 'calculated',\n",
       " 'returning',\n",
       " 'protect',\n",
       " 'covering',\n",
       " 'launched',\n",
       " 'smallbusiness',\n",
       " 'booster',\n",
       " 'worn',\n",
       " 'chinese',\n",
       " 'should',\n",
       " 'hospitality',\n",
       " 'on…',\n",
       " 'information',\n",
       " 'pregnant',\n",
       " 'how',\n",
       " 'doctor…rt',\n",
       " 'a',\n",
       " 'roundtheglobe',\n",
       " 'nearly',\n",
       " 'tak…we',\n",
       " 'great',\n",
       " 'antichinazi',\n",
       " 'dexamethasone',\n",
       " 'first',\n",
       " 'bloodymirputin',\n",
       " 'bbnnrealnews',\n",
       " 'cost',\n",
       " 'jayawardena…',\n",
       " 'vikash',\n",
       " 'educator',\n",
       " 'based',\n",
       " 'new',\n",
       " 'hell',\n",
       " 'questions',\n",
       " 'residency',\n",
       " 'heading',\n",
       " 'bureau',\n",
       " 'squawkcnbc',\n",
       " 'beijing',\n",
       " '120k',\n",
       " 'stevewh67',\n",
       " 'responsible',\n",
       " 'high',\n",
       " 'toll',\n",
       " 'your…rt',\n",
       " 'means',\n",
       " 'rebuild',\n",
       " 'economies',\n",
       " 'carry',\n",
       " 'old…in',\n",
       " 'curi…',\n",
       " 'gergerlioglueng',\n",
       " 'yasemin',\n",
       " 'custody',\n",
       " 'aforgut…rt',\n",
       " 'natemergtrust',\n",
       " '100',\n",
       " 'swab',\n",
       " 'negative',\n",
       " 'not…coronavirus',\n",
       " 'report',\n",
       " 'detected',\n",
       " 'journalist',\n",
       " 'char…',\n",
       " 'greece',\n",
       " 'however',\n",
       " 'a…visit',\n",
       " 'website',\n",
       " 'reshape',\n",
       " 'development',\n",
       " 'pmlivecom',\n",
       " 'ash',\n",
       " 'pence',\n",
       " 'overblown',\n",
       " 'fighting',\n",
       " 'lets',\n",
       " 'compassion',\n",
       " 'via',\n",
       " 'ddwjournal',\n",
       " 'update',\n",
       " 'coronavirus…this',\n",
       " 'paid',\n",
       " 'founder',\n",
       " '541',\n",
       " 'total',\n",
       " 'actress',\n",
       " 'tonto',\n",
       " 'expresses',\n",
       " 'loses',\n",
       " 'news',\n",
       " 'three',\n",
       " 'stand',\n",
       " 'china',\n",
       " 'generation',\n",
       " 'before',\n",
       " 'transmission',\n",
       " 'cycle',\n",
       " 'epictravellerco',\n",
       " 'natio…rt',\n",
       " 'socially',\n",
       " 'decided',\n",
       " '£100bn',\n",
       " 'into',\n",
       " 'schem…',\n",
       " 'roamthedomes',\n",
       " 'nursing',\n",
       " 'home',\n",
       " 'residents',\n",
       " 'likely',\n",
       " 'chart',\n",
       " 'theyre',\n",
       " 'possible',\n",
       " 'drc',\n",
       " 'socioeconomic',\n",
       " 'an…',\n",
       " 'sherrymonster44',\n",
       " 'amigodeldía',\n",
       " 'lunchrt',\n",
       " 'wellbeing',\n",
       " 'outbreak',\n",
       " '3dprinted',\n",
       " 'tactical',\n",
       " 'network',\n",
       " 'masks',\n",
       " 'following',\n",
       " 'proclamation',\n",
       " 'likapika27',\n",
       " 'curiosity',\n",
       " 'surprised',\n",
       " 'shia',\n",
       " 'inci…',\n",
       " 'reported',\n",
       " 'gurinder',\n",
       " 'insider',\n",
       " 'twomillionth',\n",
       " 'drmichellebio',\n",
       " 'representativesavail',\n",
       " 'rate',\n",
       " 'microfinanceireland',\n",
       " 'finlayd',\n",
       " 'daysweeks',\n",
       " 'vaccine',\n",
       " 'fiercebiotech',\n",
       " 'minus',\n",
       " 'summit',\n",
       " 'showing',\n",
       " 'keralites',\n",
       " 'qualify',\n",
       " 'mandatory',\n",
       " 'state',\n",
       " 'indiafightscoronavi…covid19',\n",
       " 'debunking',\n",
       " 'evidence',\n",
       " 'rid',\n",
       " 'low',\n",
       " 'share',\n",
       " 'placing',\n",
       " 'equity',\n",
       " 'due',\n",
       " 'daily',\n",
       " 'news',\n",
       " 'movie',\n",
       " 'capacity',\n",
       " 'tickets',\n",
       " 'guidance',\n",
       " 'public',\n",
       " 'could…rt',\n",
       " 'coas…grab',\n",
       " 'helping',\n",
       " 'merchants',\n",
       " 'normal…',\n",
       " 'arabia…rt',\n",
       " 'jesus',\n",
       " 'holyspirit',\n",
       " 'university',\n",
       " 'australia',\n",
       " 'informedrt',\n",
       " 'always',\n",
       " 'house',\n",
       " 'anylaurie16',\n",
       " 'facetime',\n",
       " 'palliative',\n",
       " 'nigel',\n",
       " 'jarvis',\n",
       " 'views',\n",
       " '1',\n",
       " 'thanks',\n",
       " 'dalbideu',\n",
       " 'countries',\n",
       " 'survey',\n",
       " 'pass',\n",
       " 'standwithhongkong',\n",
       " 'youcantstopus…',\n",
       " 'lifesaving',\n",
       " 'rolex',\n",
       " 'whats',\n",
       " 'electric',\n",
       " 'ventilator',\n",
       " 'by',\n",
       " 'asitha',\n",
       " 'scholar',\n",
       " 'curator',\n",
       " 'arts',\n",
       " 'delhi',\n",
       " 'experts',\n",
       " 'there',\n",
       " 'scientific',\n",
       " 'for',\n",
       " 'zero',\n",
       " 'coronavirusdo',\n",
       " 'ugh',\n",
       " 'phazerrules',\n",
       " 'were',\n",
       " 'breakingpoll',\n",
       " 'america',\n",
       " '100kdeadamericans',\n",
       " 'cetinkaya',\n",
       " 'mother',\n",
       " 'while',\n",
       " 'under',\n",
       " 'big',\n",
       " 'foundationscot',\n",
       " 'donation',\n",
       " 'day',\n",
       " 'another',\n",
       " 'hoping',\n",
       " '650',\n",
       " 'plant',\n",
       " 'citizens',\n",
       " 'condition',\n",
       " 'arabia…discussions',\n",
       " 'held',\n",
       " 'anticorruption',\n",
       " 'experienced',\n",
       " 'relatively',\n",
       " 'opening',\n",
       " 'pharma',\n",
       " 'angierasmussen',\n",
       " 'sarscov2',\n",
       " 'regina',\n",
       " 'daniel',\n",
       " 'about…',\n",
       " 'transmissionrt',\n",
       " 'denier',\n",
       " 'fears',\n",
       " 'second',\n",
       " 'wave',\n",
       " 'the',\n",
       " 'first',\n",
       " 'wave',\n",
       " 'transmissionpatients',\n",
       " 'warriors',\n",
       " 'empathy',\n",
       " 'inste…',\n",
       " 'n',\n",
       " 'leather',\n",
       " 'flogger',\n",
       " 'collaboration',\n",
       " 'filed',\n",
       " 'complaint',\n",
       " 'pocket',\n",
       " 'soumitd',\n",
       " 'friend',\n",
       " 'initiative',\n",
       " '38074',\n",
       " 'coronaviruskuwait',\n",
       " 'died',\n",
       " 'cities',\n",
       " 'across',\n",
       " 'provinces',\n",
       " 'accord…bbcworld',\n",
       " 'dikeh',\n",
       " 'she',\n",
       " 'sambitpatra',\n",
       " 'congre…rt',\n",
       " 'lament',\n",
       " 'finding',\n",
       " 'industry',\n",
       " 'superb',\n",
       " 'post',\n",
       " 'ranganaathan',\n",
       " 'unbelievably',\n",
       " 'lawmakers',\n",
       " 'see',\n",
       " 'soon',\n",
       " 'using…between',\n",
       " 'bodily',\n",
       " 'jobs',\n",
       " 'read',\n",
       " 'honoured',\n",
       " 'friends',\n",
       " 'advice',\n",
       " 'mentalhealth',\n",
       " 'incl…coronavirus',\n",
       " 'develops',\n",
       " 'forces',\n",
       " 'globalgiving',\n",
       " 'take',\n",
       " 'shine',\n",
       " 'caller',\n",
       " 'in',\n",
       " 'back',\n",
       " 'teachers',\n",
       " 'muslim',\n",
       " 'percent',\n",
       " 'retail',\n",
       " 'sales',\n",
       " 'largest',\n",
       " 'dhscgovuk',\n",
       " 'contact',\n",
       " 'caseworker',\n",
       " 'nhs',\n",
       " 'advises',\n",
       " 'fo…epidemiological',\n",
       " 'lessons',\n",
       " 'case',\n",
       " 'we',\n",
       " 'tomfitton',\n",
       " 'mfi',\n",
       " 'loan',\n",
       " 'ok',\n",
       " 'curevacagrt',\n",
       " 'mofataiwan',\n",
       " 'joins',\n",
       " 'copenhagen',\n",
       " 'president',\n",
       " 'discuss',\n",
       " 'status',\n",
       " 'enough',\n",
       " 'covid',\n",
       " 'less',\n",
       " 'ar…',\n",
       " 'come',\n",
       " 'get',\n",
       " 'announced',\n",
       " 'previous',\n",
       " 'letha…new',\n",
       " 'york',\n",
       " 'reduced',\n",
       " 'cashless',\n",
       " 'staggered',\n",
       " 'government',\n",
       " 'those',\n",
       " '10downingstreet',\n",
       " 'face',\n",
       " 'transport',\n",
       " 'southeast',\n",
       " 'adapt',\n",
       " 'monash',\n",
       " 'covid19…',\n",
       " 'yourself',\n",
       " 'aubrey',\n",
       " 'mom',\n",
       " 'dying',\n",
       " 'bed',\n",
       " 'rea…hear',\n",
       " 'tourism',\n",
       " 'bhpcomms',\n",
       " 'affects',\n",
       " 'children',\n",
       " 'barneyuob',\n",
       " 'pras…rt',\n",
       " 'study',\n",
       " 'continue',\n",
       " 'onneverforget',\n",
       " 'hongkong',\n",
       " 'drug',\n",
       " 'poor',\n",
       " 'being',\n",
       " 'chair',\n",
       " 'cms',\n",
       " 'again',\n",
       " 'borisjohnson',\n",
       " 'risk',\n",
       " 'no',\n",
       " 'infected',\n",
       " 'saudiarabias',\n",
       " 'general',\n",
       " 'authority',\n",
       " 'aviation',\n",
       " 'resumption',\n",
       " 'service',\n",
       " 'saudi',\n",
       " 'learning',\n",
       " 'masks',\n",
       " 'reduce',\n",
       " 'davidcorndc',\n",
       " 'what',\n",
       " 'dr',\n",
       " 'avacta',\n",
       " 'business',\n",
       " 'an',\n",
       " 'days',\n",
       " 'analyses',\n",
       " 'underestimated',\n",
       " 'country',\n",
       " 'fire',\n",
       " 'why',\n",
       " 'team',\n",
       " 'it',\n",
       " 'chancellor',\n",
       " 'pakistan',\n",
       " 'latest',\n",
       " 'mashwaniazhar',\n",
       " 'imran',\n",
       " 'issue',\n",
       " 'draseemmalhotra',\n",
       " 'acknowledged',\n",
       " 'obesity',\n",
       " 'complications',\n",
       " 'hispanics',\n",
       " 'still',\n",
       " 'testing',\n",
       " 'saudigazette',\n",
       " 'international',\n",
       " 'check',\n",
       " 'coronavirus',\n",
       " 'experts',\n",
       " 'early',\n",
       " 'pandemic',\n",
       " 'later',\n",
       " 'through',\n",
       " 'impact',\n",
       " 'germany',\n",
       " 'difference',\n",
       " 'scientist',\n",
       " 'aubreyhuff',\n",
       " 'don’t',\n",
       " 'which',\n",
       " 'meeting',\n",
       " 'national',\n",
       " 'coordination',\n",
       " 'ajk',\n",
       " 'major',\n",
       " 'factor',\n",
       " 'area',\n",
       " 'it’s',\n",
       " 'umbrellalane',\n",
       " 'i’m',\n",
       " 'over',\n",
       " 'north',\n",
       " 'please',\n",
       " 'civil',\n",
       " 'flight',\n",
       " 'singing',\n",
       " 'new',\n",
       " 'kuwait',\n",
       " 'overestimated',\n",
       " 'deadly',\n",
       " 'doesn’t…rt',\n",
       " 'more',\n",
       " 'look',\n",
       " 'after',\n",
       " 'allkeyshop',\n",
       " 'chief',\n",
       " 'tells',\n",
       " 'wearing',\n",
       " 'his',\n",
       " 'am',\n",
       " 'qatarstories',\n",
       " 'khan',\n",
       " 'committee',\n",
       " 'all',\n",
       " '5',\n",
       " 'is',\n",
       " 'what',\n",
       " 'if',\n",
       " 'or',\n",
       " 'this',\n",
       " 'including',\n",
       " 'mostly',\n",
       " 'had',\n",
       " 'can',\n",
       " 'made',\n",
       " 'care',\n",
       " 'all',\n",
       " 'naturenews',\n",
       " 'data',\n",
       " 'next',\n",
       " 'travel',\n",
       " 'if',\n",
       " 'defense',\n",
       " 'he',\n",
       " 'because',\n",
       " 'during',\n",
       " 'do',\n",
       " 'coronavirus…',\n",
       " 'refused',\n",
       " 'enforce',\n",
       " 'even',\n",
       " 'right',\n",
       " 'mask',\n",
       " 'today',\n",
       " 'covid',\n",
       " 'deaths',\n",
       " 'you',\n",
       " 'xijinping1',\n",
       " 'spreading',\n",
       " 'saw',\n",
       " 'fakekrkrealculpritofsushant',\n",
       " 'trend',\n",
       " 'top',\n",
       " 'please…rt',\n",
       " 'crisis',\n",
       " 'need',\n",
       " 'their',\n",
       " 'life',\n",
       " 'az',\n",
       " 'lockdown',\n",
       " 'simply',\n",
       " 'makes',\n",
       " 'world',\n",
       " 'narendramodi',\n",
       " 'we',\n",
       " 'symptoms',\n",
       " 'help',\n",
       " 'affected',\n",
       " 'karma',\n",
       " 'uk',\n",
       " '2',\n",
       " 'drericding',\n",
       " 'sheriff',\n",
       " 'it',\n",
       " 'pm',\n",
       " 'but',\n",
       " 'say',\n",
       " 'kerala',\n",
       " 'no',\n",
       " 'many',\n",
       " 'covid19',\n",
       " 'at',\n",
       " 'positive',\n",
       " 'test',\n",
       " 'as',\n",
       " 'her',\n",
       " 'about',\n",
       " 'our',\n",
       " 'not',\n",
       " 'my',\n",
       " 'any',\n",
       " 'tested',\n",
       " 'got',\n",
       " 'then',\n",
       " 'people',\n",
       " 'who',\n",
       " 'the',\n",
       " 'says',\n",
       " 'your',\n",
       " 'dear',\n",
       " 'i',\n",
       " 'coronavirus',\n",
       " 'its',\n",
       " 'out',\n",
       " 'now',\n",
       " 'just',\n",
       " 'with',\n",
       " 'they',\n",
       " 'amp',\n",
       " 'virus',\n",
       " 'was',\n",
       " 'be',\n",
       " 'by',\n",
       " 'from',\n",
       " 'how',\n",
       " 'will',\n",
       " 'have',\n",
       " 'this',\n",
       " 'covid19',\n",
       " 'are',\n",
       " 'you',\n",
       " 'that',\n",
       " 'has',\n",
       " 'is',\n",
       " 'for',\n",
       " 'covid19',\n",
       " 'on',\n",
       " 'in',\n",
       " 'a',\n",
       " 'and',\n",
       " 'of',\n",
       " 'to',\n",
       " 'coronavirus',\n",
       " 'the']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we look at the results of the clean_data function\n",
    "words = clean_data(df_tweetsDB)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.DataFrame({'word': words}) #creating a Pandas DataFrame that contains only the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.20.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.svm.classes module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.svm. Anything that cannot be imported from sklearn.svm is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator LinearSVC from version 0.20.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.preprocessing.label module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.preprocessing. Anything that cannot be imported from sklearn.preprocessing is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.20.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator _SigmoidCalibration from version 0.20.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator CalibratedClassifierCV from version 0.20.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from profanity_check import predict\n",
    "from autocorrect import Speller\n",
    "\n",
    "spell = Speller(lang='en')\n",
    "\n",
    "#function to generate the profanity of each tweet\n",
    "def offensive(df):\n",
    "    result = []\n",
    "    for word in df:\n",
    "        result.append((predict([word])==1)[0])\n",
    "    return result\n",
    "\n",
    "#function to generate a list of boolean values that corresponds to whether the tweets are misspelt or not\n",
    "def misspelt(df):\n",
    "    result = []\n",
    "    for word in df:\n",
    "        if (word[:2])==\"RT\" or (\"@\" in word) or (\"#\" in word) or (\".\" in word) or (\"'\" in word): #if a tweets contains any of these then its not misspelt\n",
    "            result.append(False)\n",
    "        else:\n",
    "            result.append(word != spell(word))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"offensive\"] = offensive(tweets[\"word\"]) #adding a 'offensive' column to our Pandas DataFrame\n",
    "tweets[\"misspelt\"] = misspelt(tweets[\"word\"]) #adding a 'misspelt' column to our Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets #visualizing results of previous additions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_offensive = tweets['offensive'].value_counts()[0] #getting the number of words that are not offensive\n",
    "offensive = tweets.shape[0] - not_offensive #subtracting the number of not offensive words from the total number of words so that we can get the number of offensive words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing a table of the results for the offensive and non-offensive words and their associated word count\n",
    "fig, ax = plt.subplots()\n",
    "fig.patch.set_visible(False)\n",
    "ax.axis('off')\n",
    "ax.axis('tight')\n",
    "df = pd.DataFrame([[not_offensive, offensive]], columns=['Non-offensive', 'Offensive'])\n",
    "ax.table(cellText=df.values, colLabels=df.columns, loc='center')\n",
    "plt.savefig(\"offensive_table\", transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctly_spelt = tweets['misspelt'].value_counts()[0]\n",
    "misspelt = tweets.shape[0] - correctly_spelt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing a table of the results for the misspelt and correctly words and their associated word count\n",
    "fig, ax = plt.subplots()\n",
    "fig.patch.set_visible(False)\n",
    "ax.axis('off')\n",
    "ax.axis('tight')\n",
    "df = pd.DataFrame([[correctly_spelt, misspelt]], columns=['Correctly Spelt', 'Misspelt'])\n",
    "ax.table(cellText=df.values, colLabels=df.columns, loc='center')\n",
    "plt.savefig(\"misspelt_table\", transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing results for offensive vs non-offensive words in a bar graph\n",
    "x_labels = ('Offensive', 'Non-offensive')\n",
    "y_pos = np.arange(len(x_labels))\n",
    "performance = [offensive, not_offensive]\n",
    "\n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, x_labels)\n",
    "plt.ylabel('Count')\n",
    "plt.title('Offensive vs Non-offensive')\n",
    "plt.savefig(\"offensive\", transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing results for misspelt vs correctly spelt words in a bar graph\n",
    "\n",
    "x_labels = ('Correctly Spelt', 'Misspelt')\n",
    "y_pos = np.arange(len(x_labels))\n",
    "performance = [correctly_spelt, misspelt]\n",
    "\n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, x_labels)\n",
    "plt.ylabel('Count')\n",
    "plt.title('Correctly Spelt vs Misspelt Words')\n",
    "plt.savefig(\"misepelt\", transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function returns the correctly spelt words\n",
    "def correct(df):\n",
    "    result = []\n",
    "    for word in df:\n",
    "        result.append(spell(word))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misspelt_words = tweets[tweets['misspelt']==True]['word']\n",
    "misspelt_words = pd.DataFrame({'misspelt word': misspelt_words})\n",
    "misspelt_words['correctly spelt'] = correct(misspelt_words['misspelt word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing results for misspelt words and their correct spelling\n",
    "misspelt_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this ends the spark session or streaming session\n",
    "streaming_context.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
